{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">sklearn is not build for deep/complex networks such as required in covnets (see below). We must go to specialized software (and potentially specialized hardware)</div>\n",
    "\n",
    "# Deep Learning Frameworks\n",
    "\n",
    "Almost all frameworks written in low-level C++/C with Python (or other scripting bindings)\n",
    "\n",
    "### Low-level frameworks\n",
    "\n",
    "   - Tensorflow (Google) Nov 2015\n",
    "   - Theano\n",
    "   - Caffe (Berkeley)\n",
    "   - Torch (Lua)\n",
    "   - pytorch (Python)\n",
    "   - CNTK (Microsoft)\n",
    "   - Chainer\n",
    "   - PaddlePaddle (Baidu) Aug 2016\n",
    "   \n",
    "### High level frameworks (Python)\n",
    "\n",
    "   - Keras (atop Tensorflow, Theano)\n",
    "   - TFLearn \n",
    "   - nolearn\n",
    "   - SkFlow (part of tensorflow)\n",
    "   - [Lasagne](http://lasagne.readthedocs.io/en/latest/index.html) (atop Theano)\n",
    "   \n",
    "<img src=\"https://pbs.twimg.com/media/DX0lfBNU8AEs8KG.png:large\" width=\"75%\">\n",
    "Source: https://twitter.com/fchollet/status/971863128341323776\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">TensorFlow is the platform of choice for deep learning in the research community. These are deep learning framework mentions on arXiv over the past 3 months <img src=\"https://pbs.twimg.com/media/DXy_uc0VAAAIhKG.jpg:small\">\n",
    "\n",
    "&mdash; Fran√ßois Chollet (@fchollet) <a href=\"https://twitter.com/fchollet/status/971863128341323776?ref_src=twsrc%5Etfw\">March 8, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "\n",
    "see also: https://github.com/mbadry1/Top-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from before\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "df = pd.read_csv(\"galspec.csv\")\n",
    "X = df[['dered_r', 'ug_color', 'gr_color', 'ri_color', 'iz_color', 'modelMagErr_u',\n",
    "       'modelMagErr_g', 'modelMagErr_r', 'modelMagErr_i', 'modelMagErr_z',\n",
    "       'fiberMag_r', 'fiber_ug', 'fiber_gr', 'fiber_ri', 'fiber_iz']]\n",
    "y = df[[\"specz\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "pt = preprocessing.PowerTransformer()  # this serves to rescale (non-linearly) the data so that it is roughly Gaussian\n",
    "X_train_scaled = pt.fit_transform(X_train)\n",
    "X_test_scaled = pt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential  # linear stack of layers\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_clf():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(15,), activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(10,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(5,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(1, activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae',\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "clf = KerasRegressor(build_fn=nn_clf, batch_size=32, epochs=50)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well did we do?\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = np.sqrt(mean_squared_error(y_test, clf.predict(X_test_scaled))) ; print(\"MSE\",mse)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"NN Regression Residuals - MSE = %.3f\" % mse)\n",
    "plt.scatter(y_test,clf.predict(X_test_scaled),alpha=0.4,s=3)\n",
    "plt.xlabel(\"Test Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.plot([0.2,1],[0.2,1.0],c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we also want to predict the error in the photometric redshift. So we can try to predict 2 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_clf_two():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_shape=(15,), activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(12,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(10,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(5,  activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(2, activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae',\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf_two().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"specz\", \"speczerr\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scales of the outputs are very different. Let's rescale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "pt = preprocessing.PowerTransformer()  \n",
    "X_train_scaled = pt.fit_transform(X_train)\n",
    "X_test_scaled = pt.transform(X_test)\n",
    "\n",
    "pty = preprocessing.PowerTransformer()\n",
    "pty.fit(y_train)\n",
    "y_train_scaled = pty.transform(y_train)\n",
    "y_test_scaled = pty.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasRegressor(build_fn=nn_clf_two, batch_size=64, epochs=100)\n",
    "clf.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well did we do?\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#mse = np.sqrt(mean_squared_error(y_test, clf.predict(X_test_scaled))) ; print(\"MSE\",mse)\n",
    "\n",
    "predicted_y = pty.inverse_transform(clf.predict(X_test_scaled))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#plt.title(\"NN Regression Residuals - MSE = %.3f\" % mse)\n",
    "plt.scatter(y_test[:,0], predicted_y[:,0],alpha=0.4,s=3)\n",
    "plt.xlabel(\"Test specz\")\n",
    "plt.ylabel(\"Predicted specz\")\n",
    "plt.plot([-1,3],[-1,3],c=\"r\")\n",
    "plt.xlim(0.2,1)\n",
    "plt.ylim(0.2,1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#plt.title(\"NN Regression Residuals - MSE = %.3f\" % mse)\n",
    "plt.scatter(y_test[:,1], predicted_y[:,1], alpha=0.4,s=3)\n",
    "plt.xlabel(\"Test specz_err\")\n",
    "plt.ylabel(\"Predicted specz_err\")\n",
    "plt.plot([0,1],[0,1],c=\"r\")\n",
    "plt.xlim(0,y_test[:,1].max())\n",
    "plt.ylim(0,y_test[:,1].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.asimovinstitute.org/wp-content/uploads/2016/09/neuralnetworks.png\">\n",
    "\n",
    "Source: http://www.asimovinstitute.org/neural-network-zoo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Nets (ConvNets)\n",
    "\n",
    "NNs built for images (or more generally, inputs with structure). **These may be useful for Lab #2**\n",
    "\n",
    "### Key Ideas: \n",
    "  - layers see only parts of each image (effectively all other weights are zero).\n",
    "  - some layers do simple operations on previous layers to reduce dimensionality (e.g., take the largest value in a a 3x3 range)\n",
    "  - \"Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.\"\n",
    " \n",
    "<img src=\"http://cs231n.github.io/assets/cnn/cnn.jpeg\">\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/depthcol.jpeg\">\n",
    "\n",
    "\"An example input volume in red (e.g. a 32x32x3 CIFAR-10 image), and an example volume of neurons in the first Convolutional layer. Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input - see discussion of depth columns in text below. \"\n",
    "\n",
    "cf. http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "<img src=\"http://www.nature.com/nature/journal/v521/n7553/images/nature14539-f2.jpg\">\n",
    "Source: http://www.nature.com/nature/journal/v521/n7553/fig_tab/nature14539_F2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/pool.jpeg\" width=\"40%\">\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/maxpool.jpeg\" width=\"40%\">\n",
    "Source: http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of understanding spectra and timeseries data in the context of convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a way to generate some 1D sources with some structure\n",
    "# set by just a few parameters\n",
    "def gen_timeseries(ts, period, harmonic_phase_amplitudes):\n",
    "    lightcurve = np.zeros(ts.shape)\n",
    "    for i, (amp, phase) in enumerate(harmonic_phase_amplitudes):\n",
    "        lightcurve += amp*np.sin(  ((i+1)*period + phase)*ts)\n",
    "    return lightcurve\n",
    "\n",
    "ts = np.arange(0, 2*np.pi, 0.01)\n",
    "n_ts = len(ts)\n",
    "\n",
    "plt.plot(ts, gen_timeseries(ts, 7, [(1.0, 0), (0.5, 0.5)]))\n",
    "plt.plot(ts, gen_timeseries(ts, 2, [(0.1, 0), (0.5, 0.1)]))\n",
    "plt.plot(ts, gen_timeseries(ts, 3.5, [(0.7, 0.1), (0.7, 0.2)]))\n",
    "print(n_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "## make some training data\n",
    "rnd = np.random.RandomState(seed=42)\n",
    "\n",
    "n_training = 2000\n",
    "n_testing = 500\n",
    "\n",
    "P_training = rnd.rand(n_training)*9 + 1 # make periods from 1-10\n",
    "ap = rnd.rand(n_training, 4)\n",
    "ap[:, 1] *= 2*np.pi\n",
    "ap[:, 3] *= 2*np.pi\n",
    "spl = np.hsplit(ap, 2)\n",
    "ampp = [[tuple(spl[0][i, :]), tuple(spl[1][i, :])] for i in range(n_training)]\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(n_training):\n",
    "    X_train.append(gen_timeseries(ts, P_training[i], ampp[i]))\n",
    "    y_train.append([P_training[i]] + list(chain(*ampp[i])))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Testing \n",
    "\n",
    "P_testing = rnd.rand(n_testing)*9 + 1 # make periods from 1-10\n",
    "ap = rnd.rand(n_testing, 4)\n",
    "ap[:, 1] *= 2*np.pi\n",
    "ap[:, 3] *= 2*np.pi\n",
    "spl = np.hsplit(ap, 2)\n",
    "ampp = [[tuple(spl[0][i, :]), tuple(spl[1][i, :])] for i in range(n_testing)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(n_testing):\n",
    "    X_test.append(gen_timeseries(ts, P_testing[i], ampp[i]))\n",
    "    y_test.append([P_testing[i]] + list(chain(*ampp[i])))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "#y_train = np.expand_dims(y_train, axis=2)\n",
    "#y_test = np.expand_dims(y_test, axis=2)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, X_train[0, :, 0])\n",
    "plt.title(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  # linear stack of layers\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, AveragePooling1D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(filters=64, kernel_size=2, input_shape=(n_ts, 1), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=2, padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "model.add(Convolution1D(filters=16, kernel_size=2, padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1)) # helps control overfitting\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(y_test.shape[1]))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(), metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "plt.plot(ts, gen_timeseries(ts, pred[ind][0],  [(pred[ind][1],pred[ind][2]), (pred[ind][3],pred[ind][4])]), label=\"pred\")\n",
    "plt.plot(ts, gen_timeseries(ts, y_test[ind][0],  [(y_test[0][1],y_test[0][2]), (y_test[0][3],y_test[0][4])]), label=\"true\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(P_testing, pred[:,0], alpha=0.2)\n",
    "plt.title(\"Period\")\n",
    "plt.xlabel(\"True period\")\n",
    "plt.ylabel(\"Predicted period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test[:, 1], pred[:,1], alpha=0.2)\n",
    "plt.title(\"Freq0 Amplitude\")\n",
    "plt.xlabel(\"True A\")\n",
    "plt.ylabel(\"Predicted A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test[:, 2], pred[:,2], alpha=0.2)\n",
    "plt.title(\"Freq0 Phase\")\n",
    "plt.xlabel(\"True Phase\")\n",
    "plt.ylabel(\"Predicted Phase\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
